{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3e83773-6505-4209-891a-3af2b86eea90",
   "metadata": {},
   "source": [
    "#### Загрузка библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da0bbcab-e451-4a19-89f9-02f076e9e9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: findspark==2.0.1 in ./.local/lib/python3.8/site-packages (2.0.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas==2.0.0 in ./.local/lib/python3.8/site-packages (2.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.8/site-packages (from pandas==2.0.0) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./.local/lib/python3.8/site-packages (from pandas==2.0.0) (2024.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas==2.0.0) (2023.3.post1)\n",
      "Requirement already satisfied: numpy>=1.20.3; python_version < \"3.10\" in ./.local/lib/python3.8/site-packages (from pandas==2.0.0) (1.24.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas==2.0.0) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy==1.24.2 in ./.local/lib/python3.8/site-packages (1.24.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: catboost==1.2.2 in ./.local/lib/python3.8/site-packages (1.2.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.8/site-packages (from catboost==1.2.2) (1.9.3)\n",
      "Requirement already satisfied: numpy>=1.16.0 in ./.local/lib/python3.8/site-packages (from catboost==1.2.2) (1.24.2)\n",
      "Requirement already satisfied: graphviz in ./.local/lib/python3.8/site-packages (from catboost==1.2.2) (0.20.3)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.8/site-packages (from catboost==1.2.2) (3.2.2)\n",
      "Requirement already satisfied: pandas>=0.24 in ./.local/lib/python3.8/site-packages (from catboost==1.2.2) (2.0.0)\n",
      "Requirement already satisfied: plotly in ./.local/lib/python3.8/site-packages (from catboost==1.2.2) (5.22.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from catboost==1.2.2) (1.16.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->catboost==1.2.2) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->catboost==1.2.2) (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->catboost==1.2.2) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib->catboost==1.2.2) (0.11.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas>=0.24->catboost==1.2.2) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./.local/lib/python3.8/site-packages (from pandas>=0.24->catboost==1.2.2) (2024.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in ./.local/lib/python3.8/site-packages (from plotly->catboost==1.2.2) (8.3.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from plotly->catboost==1.2.2) (23.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install findspark==2.0.1\n",
    "!pip install pandas==2.0.0\n",
    "!pip install numpy==1.24.2\n",
    "!pip install catboost==1.2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a3792f-9f19-4dca-81f5-28c228a35f8d",
   "metadata": {},
   "source": [
    "## Разведочный анализ датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b70b1b5-337b-4be7-8c55-44ad93b4a279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import findspark\n",
    "\n",
    "\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0420827-0940-4296-9552-c5dc2cee3e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = (\n",
    "    SparkConf().setMaster(\"yarn\").setAppName(\"EDA\")\n",
    "        .set(\"spark.executor.memory\", \"2g\")\n",
    "        .set(\"spark.driver.memory\", \"4g\")\n",
    "        .set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
    ")\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40a7e49-9af7-4962-8667-087f3ea687ed",
   "metadata": {},
   "source": [
    "Указываем типы данных для столбцов и корректные значения столбцов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "693b766b-0ca7-4533-a02d-3d7477ce5ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------------+-----------+-----------+---------+---------------+------------+--------+-----------------+\n",
      "|transaction_id|        tx_datetime|customer_id|terminal_id|tx_amount|tx_time_seconds|tx_time_days|tx_fraud|tx_fraud_scenario|\n",
      "+--------------+-------------------+-----------+-----------+---------+---------------+------------+--------+-----------------+\n",
      "|             0|2019-08-22 06:51:03|          0|        711|    70.91|          24663|           0|       0|                0|\n",
      "|             1|2019-08-22 05:10:37|          0|          0|    90.55|          18637|           0|       0|                0|\n",
      "|             2|2019-08-22 19:05:33|          0|        753|    35.38|          68733|           0|       0|                0|\n",
      "|             3|2019-08-22 07:21:33|          0|          0|    80.41|          26493|           0|       0|                0|\n",
      "|             4|2019-08-22 09:06:17|          1|        981|   102.83|          32777|           0|       0|                0|\n",
      "|             5|2019-08-22 18:41:25|          3|        205|     34.2|          67285|           0|       0|                0|\n",
      "|             6|2019-08-22 03:12:21|          3|          0|     47.2|          11541|           0|       0|                0|\n",
      "|             7|2019-08-22 22:36:40|          6|        809|   139.39|          81400|           0|       0|                0|\n",
      "|             8|2019-08-22 17:23:29|          7|        184|    87.24|          62609|           0|       0|                0|\n",
      "|             9|2019-08-22 21:09:37|          8|        931|     61.7|          76177|           0|       0|                0|\n",
      "|            10|2019-08-22 11:32:42|         10|        663|    40.71|          41562|           0|       1|                2|\n",
      "|            11|2019-08-22 03:09:26|         10|        770|    63.91|          11366|           0|       0|                0|\n",
      "|            12|2019-08-22 15:47:54|         10|          0|    58.89|          56874|           0|       0|                0|\n",
      "|            13|2019-08-22 21:59:20|         10|        649|    89.24|          79160|           0|       0|                0|\n",
      "|            14|2019-08-22 20:55:13|         11|        380|     9.89|          75313|           0|       0|                0|\n",
      "|            15|2019-08-22 16:39:03|         11|        337|    83.36|          59943|           0|       0|                0|\n",
      "|            16|2019-08-22 23:15:07|         11|        973|    35.12|          83707|           0|       0|                0|\n",
      "|            17|2019-08-22 07:39:45|         12|          9|     74.0|          27585|           0|       0|                0|\n",
      "|            18|2019-08-22 05:35:39|         12|        745|   108.63|          20139|           0|       0|                0|\n",
      "|            19|2019-08-22 10:29:16|         12|          9|    84.45|          37756|           0|       0|                0|\n",
      "+--------------+-------------------+-----------+-----------+---------+---------------+------------+--------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType, TimestampType\n",
    "\n",
    "s3_filepath = \"s3a://amamylov-mlops/2019-08-22.txt\"\n",
    "\n",
    "columns = ['transaction_id',\n",
    " 'tx_datetime',\n",
    " 'customer_id',\n",
    " 'terminal_id',\n",
    " 'tx_amount',\n",
    " 'tx_time_seconds',\n",
    " 'tx_time_days',\n",
    " 'tx_fraud',\n",
    " 'tx_fraud_scenario']\n",
    "\n",
    "#задаем типы данных для фичей\n",
    "schema = StructType([\n",
    "    StructField(\"transaction_id\", IntegerType(), True),\n",
    "    StructField(\"tx_datetime\", TimestampType(), True),\n",
    "    StructField(\"customer_id\", IntegerType(), True),\n",
    "    StructField(\"terminal_id\", IntegerType(), True),\n",
    "    StructField(\"tx_amount\", DoubleType(), True),\n",
    "    StructField(\"tx_time_seconds\", IntegerType(), True),\n",
    "    StructField(\"tx_time_days\", IntegerType(), True),\n",
    "    StructField(\"tx_fraud\", IntegerType(), True),\n",
    "    StructField(\"tx_fraud_scenario\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "sdf = spark.read. \\\n",
    "        option(\"sep\", \",\"). \\\n",
    "        option(\"comment\", \"#\"). \\\n",
    "        schema(schema). \\\n",
    "        csv(s3_filepath, header=False).toDF(*columns)\n",
    "\n",
    "sdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e84d3a2e-2112-44bd-a566-ea9beed0089e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- transaction_id: integer (nullable = true)\n",
      " |-- tx_datetime: timestamp (nullable = true)\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- terminal_id: integer (nullable = true)\n",
      " |-- tx_amount: double (nullable = true)\n",
      " |-- tx_time_seconds: integer (nullable = true)\n",
      " |-- tx_time_days: integer (nullable = true)\n",
      " |-- tx_fraud: integer (nullable = true)\n",
      " |-- tx_fraud_scenario: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032be521-ab64-486f-ba07-4d1e75a25c2c",
   "metadata": {},
   "source": [
    "Давайте рассмотрим значения каждой колонки (фичи) в предложенной таблице данных:\n",
    "1. transaction_id - Уникальный идентификатор транзакции. Это числовое значение, которое служит для идентификации каждой отдельной транзакции в датасете.\n",
    "2. tx_datetime - Дата и время проведения транзакции. Это строка или объект datetime, который указывает точное время, когда транзакция была выполнена.\n",
    "3. customer_id - Идентификатор клиента, который совершил транзакцию. Это числовой идентификатор, присвоенный каждому клиенту, и он используется для отслеживания транзакций, совершенных одним и тем же клиентом.\n",
    "4. terminal_id - Идентификатор терминала, на котором была проведена транзакция. Это число, которое идентифицирует физическое устройство или место, где транзакция была выполнена (например, банкомат или терминал в магазине).\n",
    "5. tx_amount - Сумма транзакции. Это числовое значение, которое указывает на общую сумму денег, переданных в ходе транзакции.\n",
    "6. tx_time_seconds - Время транзакции в секундах с начала дня. Это числовое значение, показывающее, сколько секунд прошло с полуночи до момента совершения транзакции.\n",
    "7. tx_time_days - Количество дней с начала наблюдения до даты транзакции. Это число указывает, на какой день после начала сбора данных произошла транзакция.\n",
    "8. tx_fraud - Индикатор мошенничества. Это бинарное значение (0 или 1), где 1 указывает на то, что транзакция была мошеннической, а 0 — что транзакция была законной.\n",
    "9. tx_fraud_scenario - Сценарий мошенничества. Это числовое значение, которое описывает тип мошенничества, если оно имело место (если tx_fraud = 1). Различные числа могут соответствовать разным сценариям мошенничества, например, кража карты, фишинг и т.д."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31aa8159-d265-47a9-8240-2ec65e9614ca",
   "metadata": {},
   "source": [
    "Сортируем датафрейм по времени, так как исходный не отсортирован"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0f07d63-c182-4204-a68e-a587dca20893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------+-----------+-----------+---------+---------------+------------+--------+-----------------+\n",
      "|transaction_id|tx_datetime|customer_id|terminal_id|tx_amount|tx_time_seconds|tx_time_days|tx_fraud|tx_fraud_scenario|\n",
      "+--------------+-----------+-----------+-----------+---------+---------------+------------+--------+-----------------+\n",
      "|      15100839|       null|     643855|        287|    42.93|         864000|           9|       0|                0|\n",
      "|      18342252|       null|     713099|        936|   101.43|        1036800|          11|       0|                0|\n",
      "|      20002662|       null|     773093|        343|     9.71|        1123200|          12|       1|                2|\n",
      "|      19354697|       null|     359525|        616|     9.58|        1123200|          12|       0|                0|\n",
      "|      16438382|       null|     498350|        615|   140.26|         950400|          10|       0|                0|\n",
      "|      22571066|       null|     412353|         32|    90.91|        1296000|          14|       0|                0|\n",
      "|      20629738|       null|     173429|        685|    55.75|        1209600|          13|       0|                0|\n",
      "|      21020517|       null|     422579|        511|    48.73|        1209600|          13|       0|                0|\n",
      "|       1543099|       null|     985197|        967|    85.18|          86400|           0|       0|                0|\n",
      "|       1670385|       null|      66533|        956|    21.39|         172800|           1|       0|                0|\n",
      "|       1205236|       null|     769896|         44|     15.1|          86400|           0|       0|                0|\n",
      "|       4576892|       null|     922295|        241|    59.82|         259200|           2|       0|                0|\n",
      "|       2615257|       null|     669953|        489|    40.75|         172800|           1|       0|                0|\n",
      "|       3036595|       null|     938860|        481|    13.52|         172800|           1|       0|                0|\n",
      "|       1164488|       null|     743659|          0|     7.25|          86400|           0|       0|                0|\n",
      "|       3837780|       null|     450941|        847|    40.38|         259200|           2|       0|                0|\n",
      "|        933817|       null|     597125|        611|    62.83|          86400|           0|       0|                0|\n",
      "|       2898079|       null|     850307|        532|    14.26|         172800|           1|       0|                0|\n",
      "|       1781446|       null|     137885|        124|     13.7|         172800|           1|       0|                0|\n",
      "|       3854919|       null|     461823|          0|    58.44|         259200|           2|       0|                0|\n",
      "+--------------+-----------+-----------+-----------+---------+---------------+------------+--------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "sdf = sdf.orderBy(col(\"tx_datetime\"))\n",
    "sdf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cce353-f504-4455-ad09-72688b803838",
   "metadata": {},
   "source": [
    "Проверяем количество null в столбце времени. Если их немного можем удалить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22ad07ab-2a7a-4739-829f-4f744f44a9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Общее количество строк: 46988418\n",
      "Количество строк с null в tx_datetime: 100\n",
      "Процент строк с null в tx_datetime: 0.00%\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "total_count = sdf.count()\n",
    "# Фильтрация строк, где tx_datetime является null\n",
    "null_count = sdf.filter(col(\"tx_datetime\").isNull()).count()\n",
    "null_percentage = (null_count / total_count) * 100\n",
    "\n",
    "print(f\"Общее количество строк: {total_count}\")\n",
    "print(f\"Количество строк с null в tx_datetime: {null_count}\")\n",
    "print(f\"Процент строк с null в tx_datetime: {null_percentage:.2f}%\")\n",
    "\n",
    "# Удаление строк, где tx_datetime равно null\n",
    "sdf = sdf.na.drop(subset=[\"tx_datetime\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e073e69-a49f-440a-b9e4-35c3a1853a9f",
   "metadata": {},
   "source": [
    "Проверяем transaction_id на уникальность. Если есть записи больше одной, то удаляем следующие за ней."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23762f4b-fb8b-42d1-b7f9-d24b285e5f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Есть повторяющиеся transaction_id. Количество повторений: 181\n",
      "+--------------+-----+\n",
      "|transaction_id|count|\n",
      "+--------------+-----+\n",
      "|       5133913|    2|\n",
      "|      13463161|    2|\n",
      "|      11403446|    2|\n",
      "|       7052242|    2|\n",
      "|      17098584|    2|\n",
      "|      17517624|    2|\n",
      "|      35909184|    2|\n",
      "|       7365855|    2|\n",
      "|      15879594|    2|\n",
      "|      13885299|    2|\n",
      "|       5881543|    2|\n",
      "|       5349542|    2|\n",
      "|      35502726|    2|\n",
      "|      38290377|    2|\n",
      "|      24822180|    2|\n",
      "|      18933927|    2|\n",
      "|      13075936|    2|\n",
      "|      24319383|    2|\n",
      "|      40445669|    2|\n",
      "|      23385554|    2|\n",
      "+--------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Группировка по transaction_id и подсчет количества каждого идентификатора\n",
    "duplicate_counts = sdf.groupBy(\"transaction_id\").count()\n",
    "\n",
    "# Фильтрация результатов, чтобы найти те, где количество больше 1\n",
    "duplicates = duplicate_counts.filter(col(\"count\") > 1).orderBy(col(\"count\").desc())\n",
    "\n",
    "duplicate_count = duplicates.count()\n",
    "if duplicate_count > 0:\n",
    "    print(f\"Есть повторяющиеся transaction_id. Количество повторений: {duplicate_count}\")\n",
    "    duplicates.show()\n",
    "else:\n",
    "    print(\"Повторяющихся transaction_id нет.\")\n",
    "    \n",
    "sdf = sdf.dropDuplicates(['transaction_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045591b1-1ecd-41c4-92bf-a2933a7b0d64",
   "metadata": {},
   "source": [
    "Проверим есть ли в строках полные дубликаты. Проверять будем по всем колонкам кроме времени"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f057ab8-f245-462f-9ccc-3f88593cb99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество строк до удаления дубликатов: 46988137\n",
      "Количество строк после удаления дубликатов: 46988137\n"
     ]
    }
   ],
   "source": [
    "# Список всех столбцов, кроме 'tx_datetime'\n",
    "columns_to_check = [col_name for col_name in sdf.columns if col_name != 'tx_datetime']\n",
    "unique_df = sdf.dropDuplicates(columns_to_check)\n",
    "\n",
    "print(f\"Количество строк до удаления дубликатов: {sdf.count()}\")\n",
    "print(f\"Количество строк после удаления дубликатов: {unique_df.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0da354b-9fac-40cf-83b0-71faad58aa9c",
   "metadata": {},
   "source": [
    "Дубликатов больше нет, все хорошо! Теперь проверим есть ли аномалии в соответствиях фрода и его сценария. Все легитимные операции должны быть со сценарием 0. А фродовые операциями со сценариями 1,2,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9cb5a2d-e28c-4fb9-9052-1b9f7923747c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+--------+\n",
      "|tx_fraud|tx_fraud_scenario|   count|\n",
      "+--------+-----------------+--------+\n",
      "|       1|                2| 2435433|\n",
      "|       1|                1|   25653|\n",
      "|       1|                3|   65895|\n",
      "|       0|                0|44461156|\n",
      "+--------+-----------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Группировка данных по столбцам tx_fraud и tx_fraud_scenario и подсчет количества записей для каждой комбинации\n",
    "fraud_report = sdf.groupBy(\"tx_fraud\", \"tx_fraud_scenario\").count()\n",
    "fraud_report.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d96fdb5-1774-4b57-a63b-7e984c233644",
   "metadata": {},
   "source": [
    "Распределение меток правильное, все хорошо! Теперь проверим id, чтобы не было отрицательных значений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56cf2bb2-d36c-487f-b636-5e67be81f478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Есть строки с отрицательными значениями ID.\n",
      "+--------------+-------------------+-----------+-----------+---------+---------------+------------+--------+-----------------+\n",
      "|transaction_id|        tx_datetime|customer_id|terminal_id|tx_amount|tx_time_seconds|tx_time_days|tx_fraud|tx_fraud_scenario|\n",
      "+--------------+-------------------+-----------+-----------+---------+---------------+------------+--------+-----------------+\n",
      "|       8652632|2019-08-27 03:52:56|    -999999|        561|    74.97|         445976|           5|       0|                0|\n",
      "|      30318659|2019-09-10 09:28:44|    -999999|         81|    55.97|        1675724|          19|       0|                0|\n",
      "|      13931349|2019-08-30 17:41:54|    -999999|        936|    88.35|         754914|           8|       0|                0|\n",
      "|      11061761|2019-08-29 16:15:09|    -999999|        473|     47.9|         663309|           7|       0|                0|\n",
      "|      44445421|2019-09-19 06:59:51|    -999999|        740|   183.25|        2444391|          28|       0|                0|\n",
      "|       5740668|2019-08-25 01:00:46|    -999999|        274|     1.76|         262846|           3|       0|                0|\n",
      "|       7301532|2019-08-26 11:49:23|    -999999|        995|   129.96|         388163|           4|       0|                0|\n",
      "|       2710771|2019-08-23 09:46:25|    -999999|        947|     8.07|         121585|           1|       0|                0|\n",
      "|      20597326|2019-09-04 06:08:26|    -999999|        263|   116.01|        1145306|          13|       0|                0|\n",
      "|       9453882|2019-08-28 21:15:24|    -999999|        256|   114.29|         594924|           6|       0|                0|\n",
      "|      28240834|2019-09-09 10:13:48|    -999999|        243|    21.68|        1592028|          18|       0|                0|\n",
      "|      45667318|2019-09-20 08:48:22|    -999999|        904|     5.51|        2537302|          29|       0|                0|\n",
      "|      19889842|2019-09-03 10:18:45|    -999999|        988|    92.86|        1073925|          12|       0|                0|\n",
      "|       1974447|2019-08-23 11:56:00|    -999999|        919|     22.9|         129360|           1|       0|                0|\n",
      "|      42295400|2019-09-18 10:31:16|    -999999|        786|     17.4|        2370676|          27|       0|                0|\n",
      "|      34867348|2019-09-13 16:14:05|    -999999|         29|   181.08|        1959245|          22|       0|                0|\n",
      "|      20571546|2019-09-04 12:57:35|    -999999|        847|    51.92|        1169855|          13|       0|                0|\n",
      "|      24849348|2019-09-06 09:52:12|    -999999|         81|     22.9|        1331532|          15|       0|                0|\n",
      "|       2575141|2019-08-23 18:05:39|    -999999|        845|    37.24|         151539|           1|       0|                0|\n",
      "|      14058892|2019-08-30 12:00:48|    -999999|         81|    43.28|         734448|           8|       0|                0|\n",
      "+--------------+-------------------+-----------+-----------+---------+---------------+------------+--------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "id_columns = ['transaction_id', 'customer_id', 'terminal_id']\n",
    "\n",
    "# Фильтрация строк с отрицательными значениями в любой из колонок\n",
    "negative_values = sdf.filter(\n",
    "    (col('transaction_id') < 0) |\n",
    "    (col('customer_id') < 0) |\n",
    "    (col('terminal_id') < 0)\n",
    ")\n",
    "\n",
    "if negative_values.count() > 0:\n",
    "    print(\"Есть строки с отрицательными значениями ID.\")\n",
    "    negative_values.show()\n",
    "else:\n",
    "    print(\"Отрицательные значения в ID не найдены.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f3d4840-102d-4661-9c50-4b0325d51084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание нового DataFrame без строк, где ID отрицательные\n",
    "sdf = sdf.filter(\n",
    "    (col('transaction_id') >= 0) &\n",
    "    (col('customer_id') >= 0) &\n",
    "    (col('terminal_id') >= 0)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30568dc-248a-423d-b345-a61cf4f0d4c8",
   "metadata": {},
   "source": [
    "Сохранение обработанного датафрейма в s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42aa1598-9160-44eb-811f-2555248c40ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_to_s3 = SparkSession.builder \\\n",
    "    .appName(\"Write DataFrame to S3\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", \"ACCESS_KEY\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", \"SECRET_KEY\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"storage.yandexcloud.net\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0a405f4-4ac4-45c5-9bbf-edb02b03d41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"s3a://amamylov-mlops/2019-08-22.parquet\"\n",
    "sdf.write.parquet(output_path, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5308e9cd-8535-42a8-9480-b01085be2298",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_to_s3.stop()\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
